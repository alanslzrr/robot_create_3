# Integraci√≥n MCP - Robot Create3 Navegaci√≥n Topol√≥gica

## Resumen

Este proyecto implementa un sistema completo de control por voz del robot iRobot Create3 mediante Model Context Protocol (MCP) e integraci√≥n con OpenAI Realtime API. El sistema permite controlar la navegaci√≥n topol√≥gica del robot mediante comandos de voz naturales, manteniendo toda la l√≥gica de navegaci√≥n robusta existente intacta.

## Arquitectura del Sistema

El sistema utiliza **FastMCP con transporte SSE (Server-Sent Events)** para una conexi√≥n robusta y persistente entre componentes. Consta de 5 componentes principales:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    WebSocket    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    WebSocket    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ                 ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ                 ‚îÇ
‚îÇ   Navegador     ‚îÇ    Audio/JSON   ‚îÇ  robot_bridge   ‚îÇ    Audio/JSON   ‚îÇ  OpenAI Realtime‚îÇ
‚îÇ   (index.html)  ‚îÇ                 ‚îÇ   (puerto 8000) ‚îÇ                 ‚îÇ       API       ‚îÇ
‚îÇ                 ‚îÇ                 ‚îÇ                 ‚îÇ                 ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ
                                             ‚îÇ SSE (HTTP)
                                             ‚îÇ
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ                 ‚îÇ
                                    ‚îÇ   mcp_server    ‚îÇ
                                    ‚îÇ  (puerto 8001)  ‚îÇ
                                    ‚îÇ                 ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚îÇ
                                             ‚îÇ Python directo
                                             ‚îÇ
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     Bluetooth     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ                 ‚îÇ ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ                 ‚îÇ
                                    ‚îÇ robot_service   ‚îÇ                   ‚îÇ  Robot Create3  ‚îÇ
                                    ‚îÇ                 ‚îÇ                   ‚îÇ                 ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1. robot_bridge.py - Servidor Bridge Principal (Puerto 8000)

Servidor FastAPI que act√∫a como puente bidireccional entre el navegador del usuario, OpenAI Realtime API y el servidor MCP del robot. Responsabilidades:

- Servidor HTTP en puerto 8000 con FastAPI
- Endpoint WebSocket `/ws` para comunicaci√≥n con el navegador
- Conexi√≥n WebSocket a OpenAI Realtime API
- **Conexi√≥n SSE al servidor MCP** (m√°s robusto que stdio)
- Traducci√≥n de protocolos: audio del browser ‚Üí OpenAI, llamadas de herramientas OpenAI ‚Üí MCP
- Manejo de transcripciones bidireccionales (usuario ‚Üí IA, IA ‚Üí usuario)
- Ejecuci√≥n de herramientas MCP cuando OpenAI las solicita
- Env√≠o de respuestas de voz de la IA al navegador
- Polling de telemetr√≠a cada 1 segundo (reducido de 500ms para evitar conflictos durante navegaci√≥n)

Clase principal: `BridgeSession` que gestiona el ciclo de vida completo de una sesi√≥n de voz.

### 2. static/index.html (600 l√≠neas) - Interfaz Web

Interfaz web completa para control por voz del robot. Funcionalidades:

- Captura de audio del micr√≥fono del navegador mediante MediaRecorder API
- WebSocket client para comunicaci√≥n con robot_bridge.py
- Visualizaci√≥n de transcripciones en tiempo real (usuario y asistente)
- Panel de estado del robot (nodo actual, nodo destino, estado de navegaci√≥n)
- **NUEVO:** Telemetr√≠a en vivo (posici√≥n X, Y, orientaci√≥n Œ∏ con actualizaci√≥n a 2 Hz)
- **NUEVO:** Detecci√≥n autom√°tica de eventos de finalizaci√≥n de misi√≥n
- Logs del sistema en tiempo real
- Reproducci√≥n de respuestas de voz de la IA
- UI responsiva con CSS moderno y animaciones de actualizaci√≥n

### 3. robot_service.py (400+ l√≠neas) - Controlador del Robot

Controlador central que encapsula toda la l√≥gica de navegaci√≥n. Responsabilidades:

- Gesti√≥n de conexi√≥n Bluetooth persistente al robot Create3
- Mantenimiento de estado interno (nodo actual, misi√≥n activa, estado, heading)
- **NUEVO:** Persistencia de heading en `last_state.json` para navegaci√≥n consecutiva correcta
- **NUEVO:** Ejecuci√≥n de navegaci√≥n en `NavigationThread` con event loop dedicado (evita conflictos con FastMCP)
- **NUEVO:** Sistema de obtenci√≥n de heading real del robot antes de iniciar navegaci√≥n
- **NUEVO:** Deshabilitaci√≥n de loggers (`disable_logging=True`) para evitar conflictos de event loop
- Integraci√≥n con `CombinedPotentialNavigator` con par√°metro `disable_logging` para modo MCP
- Planificaci√≥n de rutas con algoritmo de Dijkstra sobre grafo topol√≥gico
- Construcci√≥n de waypoints intermedios desde el grafo
- Manejo de paradas de emergencia y cancelaciones

Clase principal: `RobotController` con m√©todos `start_navigation()`, `emergency_stop()`, `get_status()`, `set_telemetry_callback()`.

### 4. mcp_server.py - Servidor MCP (Puerto 8001)

Servidor MCP que expone las capacidades del robot como herramientas est√°ndar MCP. Funcionalidades:

- **Servidor MCP con transporte SSE (Server-Sent Events)**
- Endpoint SSE en `http://localhost:8001/sse`
- Endpoint de mensajes en `http://localhost:8001/messages`
- Protocolo JSON-RPC 2.0 para comunicaci√≥n
- 4 herramientas expuestas:
  - `list_available_locations()`: Lista nodos del mapa topol√≥gico
  - `navigate_robot(destination_id, origin_id)`: Inicia navegaci√≥n a un nodo (**origin_id ahora REQUERIDO**)
  - `emergency_stop()`: Detiene el robot inmediatamente
  - `get_robot_status()`: Consulta estado actual del robot (incluye `last_heading`)
- Instancia persistente de `RobotController` durante toda la vida del servidor
- Logging estructurado con timestamps

### 5. Componentes Existentes (Sin Modificaciones)

- `PRM02_P02_EQUIPO1_grafos.py`: Clase `CombinedPotentialNavigator` (l√≠neas 330-831) con navegaci√≥n reactiva usando campos de potencial combinados
- `grafos/prueba.py`: Carga de grafo desde JSON, algoritmo de Dijkstra, estructura de datos del grafo
- `src/config.py`: Par√°metros calibrados experimentalmente (K_REPULSIVE=300.0, D_INFLUENCE=100.0, etc.)
- `src/potential_fields.py`: C√°lculo de fuerzas atractivas y repulsivas

## Flujo de Datos Completo

```
Usuario (Navegador Web)
    ‚Üì WebSocket (audio chunks PCM16)
robot_bridge.py (Puerto 8000)
    ‚Üì WebSocket (audio base64)
OpenAI Realtime API
    ‚Üì JSON (transcripciones, llamadas a herramientas)
robot_bridge.py
    ‚Üì SSE/HTTP (JSON-RPC 2.0)
mcp_server.py (Puerto 8001)
    ‚Üì Llamadas directas Python
robot_service.py
    ‚Üì Bluetooth + iRobot SDK
Robot Create3 F√≠sico
```

### Flujo de Telemetr√≠a en Vivo (NUEVO)

```
Robot Create3 F√≠sico
    ‚Üì Bluetooth (get_position(), get_ir_proximity())
robot_service.py
    ‚Üì Bucle de telemetr√≠a (5 Hz durante navegaci√≥n)
    ‚Üì Callback con datos de posici√≥n/sensores
[Actualmente sin callback - se usa polling]
    ‚Üë Polling cada 500ms (2 Hz)
robot_bridge.py
    ‚Üì stdio JSON-RPC (get_robot_status)
mcp_server.py
    ‚Üì WebSocket JSON
Navegador Web
    ‚Üì Actualizaci√≥n UI en tiempo real
Usuario ve posici√≥n X, Y, Œ∏ en vivo
```

### Sistema de Telemetr√≠a en Vivo (NUEVO)

El sistema ahora incluye telemetr√≠a en tiempo real que env√≠a la posici√≥n del robot al navegador durante la navegaci√≥n:

### Arquitectura de Telemetr√≠a

**1. En robot_service.py:**
- Bucle de telemetr√≠a paralelo durante `_run_mission()`
- Se ejecuta a 5 Hz (cada 200ms) mientras `state == "NAVIGATING"`
- Lee posici√≥n del robot: `await robot.get_position()` ‚Üí (x, y, heading)
- Lee sensores IR: `await robot.get_ir_proximity()` ‚Üí array de 7 lecturas
- Invoca callback con datos estructurados

**2. En robot_bridge.py:**
- Tarea 3 en `communication_loop()`: `telemetry_polling()`
- Consulta `get_robot_status()` v√≠a MCP cada 500ms (2 Hz)
- Env√≠a eventos `telemetry` al navegador con posici√≥n actualizada
- Detecta autom√°ticamente eventos de finalizaci√≥n de misi√≥n
- Env√≠a eventos `mission_event` cuando una misi√≥n completa o falla

**3. En static/index.html:**
- Panel "Posici√≥n en Vivo" con valores X, Y, Œ∏
- Actualizaci√≥n en tiempo real con animaci√≥n visual
- Timestamp de √∫ltima actualizaci√≥n
- Indicador de estado de navegaci√≥n

### Datos de Telemetr√≠a

Cada paquete de telemetr√≠a incluye:

```json
{
  "timestamp": 123456.789,
  "position": {
    "x": 45.67,
    "y": 123.45,
    "theta": 90.0
  },
  "state": "NAVIGATING",
  "current_node": 0,
  "target_node": 3,
  "ir_sensors": [200, 150, 100, 50, 100, 150, 200],
  "mission_completed": false
}
```

### Eventos de Misi√≥n

Cuando una navegaci√≥n termina, se env√≠a autom√°ticamente:

```json
{
  "event": "mission_completed",
  "success": true,
  "destination_node": 3,
  "position": {"x": 50.0, "y": 120.0, "theta": 0.0},
  "message": "Llegada exitosa al Nodo 3."
}
```

### Frecuencias de Actualizaci√≥n

- **Telemetr√≠a del robot ‚Üí robot_service:** 5 Hz (cada 200ms) durante navegaci√≥n
- **Polling bridge ‚Üí MCP:** 1 Hz (cada 1 segundo) continuamente (reducido de 500ms para evitar conflictos)
- **Actualizaci√≥n UI navegador:** En tiempo real al recibir datos

Este dise√±o balancea responsividad vs overhead de red/CPU y evita conflictos de event loop durante navegaci√≥n.

## Ejemplo de Flujo: Usuario dice "Vete al nodo 3"

1. Browser captura audio del micr√≥fono y env√≠a chunks v√≠a WebSocket a robot_bridge.py
2. robot_bridge.py convierte audio a base64 y reenv√≠a a OpenAI Realtime API
3. OpenAI transcribe: "Vete al nodo 3" y env√≠a evento `conversation.item.input_audio_transcription.completed`
4. robot_bridge.py muestra transcripci√≥n en la interfaz web
5. OpenAI decide llamar herramienta y env√≠a `response.function_call_arguments.done` con `name: "navigate_robot"` y `arguments: {"destination_id": 3, "origin_id": 0}`
6. robot_bridge.py ejecuta `mcp_session.call_tool("navigate_robot", args)` que comunica con mcp_server.py v√≠a stdio
7. mcp_server.py llama `controller.start_navigation(destination_id=3, origin_id=0)`
8. robot_service.py valida par√°metros, calcula ruta con Dijkstra, crea `CombinedPotentialNavigator` y lanza navegaci√≥n en background
9. robot_service.py retorna mensaje inmediato: "RECIBIDO: Iniciando navegaci√≥n desde Nodo 0 hacia Nodo 3"
10. El resultado se propaga de vuelta: robot_service.py ‚Üí mcp_server.py ‚Üí robot_bridge.py ‚Üí OpenAI
11. OpenAI genera respuesta de voz: "De acuerdo, yendo al nodo 3"
12. robot_bridge.py recibe chunks de audio de OpenAI y los reenv√≠a al navegador
13. Usuario escucha la respuesta mientras el robot se mueve f√≠sicamente
14. **NUEVO:** Mientras el robot navega:
    - robot_service.py env√≠a telemetr√≠a cada 200ms (posici√≥n X, Y, Œ∏)
    - robot_bridge.py consulta estado cada 500ms v√≠a `get_robot_status()`
    - Navegador actualiza panel "Posici√≥n en Vivo" en tiempo real
    - Usuario ve el robot moverse en las coordenadas X, Y
15. **NUEVO:** Al llegar al destino:
    - robot_service.py env√≠a evento `mission_completed`
    - Bridge detecta cambio de estado `NAVIGATING` ‚Üí `IDLE`
    - Navegador muestra mensaje "‚úÖ Misi√≥n completada" autom√°ticamente
    - OpenAI puede ser notificado del evento para comentar (opcional)

## Instalaci√≥n

### Dependencias Requeridas

```bash
pip install mcp fastapi uvicorn websockets python-dotenv pydub aiohttp
```

**CR√çTICO:** Tambi√©n necesitas `ffmpeg` instalado en tu sistema para la conversi√≥n de audio:
- **Windows:** Descargar de https://ffmpeg.org/ y agregar al PATH
- **Linux:** `sudo apt-get install ffmpeg`
- **macOS:** `brew install ffmpeg`

Dependencias ya existentes en el proyecto:
- `irobot-edu-sdk`: SDK oficial del Create3
- `asyncio`: Est√°ndar en Python 3.7+

### Estructura de Archivos del Proyecto

```
FinalPROYECT/
‚îú‚îÄ‚îÄ start_services.bat           # Script de inicio para Windows CMD
‚îú‚îÄ‚îÄ start_services.ps1           # Script de inicio para PowerShell
‚îú‚îÄ‚îÄ mcp_server.py                # Servidor MCP con transporte SSE (puerto 8001)
‚îú‚îÄ‚îÄ robot_bridge.py              # Servidor bridge FastAPI (puerto 8000)
‚îú‚îÄ‚îÄ robot_service.py             # Controlador del robot
‚îú‚îÄ‚îÄ static/
‚îÇ   ‚îî‚îÄ‚îÄ index.html               # Interfaz web
‚îú‚îÄ‚îÄ last_state.json              # Estado persistente
‚îú‚îÄ‚îÄ .env                         # Configuraci√≥n (ver abajo)
‚îú‚îÄ‚îÄ PRM02_P02_EQUIPO1_grafos.py  # Existente - Navegaci√≥n (sin cambios)
‚îú‚îÄ‚îÄ grafos/
‚îÇ   ‚îú‚îÄ‚îÄ prueba.py                # Existente - Manejo de grafo (sin cambios)
‚îÇ   ‚îî‚îÄ‚îÄ grafo.json               # Existente - Definici√≥n del mapa
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ config.py                 # Existente - Par√°metros calibrados (sin cambios)
    ‚îî‚îÄ‚îÄ potential_fields.py       # Existente - C√°lculo de fuerzas (sin cambios)
```

## Configuraci√≥n Inicial

### 1. Configurar API Key de OpenAI

Crear archivo `.env` en la ra√≠z del proyecto:

```
# OpenAI API Key (requerida)
OPENAI_API_KEY=sk-proj-tu-clave-aqui

# URL del servidor MCP (opcional, por defecto http://localhost:8001/sse)
MCP_SERVER_URL=http://localhost:8001/sse
```

Obtener clave en: https://platform.openai.com/api-keys

### 2. Verificar Estado del Robot (Opcional)

Si es la primera vez, el sistema no conocer√° la ubicaci√≥n inicial. Opciones:

- Proporcionar `origin_id` expl√≠citamente en la primera navegaci√≥n
- Editar `last_state.json` manualmente:
```json
{
  "current_node": 0,
  "last_message": "Posici√≥n inicial configurada manualmente"
}
```

## Uso del Sistema

### Opci√≥n 1: Inicio Autom√°tico (Recomendado)

Usar el script de inicio que abre ambos servidores autom√°ticamente:

**Windows (PowerShell):**
```powershell
.\start_services.ps1
```

**Windows (CMD):**
```cmd
start_services.bat
```

### Opci√≥n 2: Inicio Manual

Abrir **dos terminales** y ejecutar en orden:

**Terminal 1 - Servidor MCP (puerto 8001):**
```bash
python mcp_server.py
```

Output esperado:
```
============================================================
SERVIDOR MCP - ROBOT CREATE3 NAVIGATOR
============================================================
Host: 0.0.0.0
Puerto: 8001
SSE Endpoint: http://0.0.0.0:8001/sse
Messages Endpoint: http://0.0.0.0:8001/messages
============================================================
[...] Controlador inicializado correctamente
Iniciando servidor MCP con transporte SSE...
```

**Terminal 2 - Robot Bridge (puerto 8000):**
```bash
python robot_bridge.py
```

Output esperado:
```
============================================================
ROBOT CREATE3 BRIDGE SERVER
============================================================
Servidor: http://0.0.0.0:8000
Interfaz Web: http://0.0.0.0:8000/
WebSocket: ws://0.0.0.0:8000/ws
Health Check: http://0.0.0.0:8000/health
============================================================
MCP Server URL: http://localhost:8001/sse
============================================================
OpenAI API Key configurada

Iniciando servidor...
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### Acceder a la Interfaz Web

1. Abrir navegador en: http://localhost:8000
2. Clic en "Iniciar Sesi√≥n de Voz"
3. Permitir acceso al micr√≥fono cuando el navegador lo solicite
4. Comenzar a hablar con el robot

### Herramientas MCP Disponibles

### 1. list_available_locations()

Lista todos los nodos del mapa topol√≥gico con sus IDs num√©ricos y nombres descriptivos.

Retorna: String formateado con lista de ubicaciones
```
Lugares del Mapa:
- ID 0: inicio
- ID 1: izq_0
- ID 2: izq_1
...
```

Uso desde voz: "¬øA d√≥nde puedes ir?" o "Lista los nodos disponibles"

### 2. navigate_robot(destination_id: int, origin_id: int)

Inicia navegaci√≥n del robot hacia un nodo destino. La funci√≥n retorna inmediatamente y la navegaci√≥n f√≠sica contin√∫a en background.

**IMPORTANTE:** `origin_id` es ahora **REQUERIDO**. Si no conoces el origen, llama primero a `get_robot_status()` para obtener `current_node`.

Par√°metros:
- `destination_id`: ID num√©rico del nodo destino (obligatorio)
- `origin_id`: ID num√©rico del nodo origen (**obligatorio**). Usa `current_node` de `get_robot_status()` si no lo conoces.

Retorna: Mensaje de confirmaci√≥n
```
"RECIBIDO: Iniciando navegaci√≥n desde Nodo 0 ('inicio') hacia Nodo 3 ('izq_2')."
```

Comportamiento interno:
1. Valida que no haya misi√≥n activa (estado != "NAVIGATING")
2. Valida que ambos nodos est√©n en rango [0, graph.V-1]
3. **NUEVO:** Obtiene heading real del robot antes de iniciar (cr√≠tico para navegaci√≥n consecutiva)
4. Calcula ruta √≥ptima con Dijkstra
5. Construye q_i, waypoints, q_f desde coordenadas del grafo
6. **NUEVO:** Crea `CombinedPotentialNavigator` con `disable_logging=True` (evita conflictos de event loop)
7. **NUEVO:** Lanza navegaci√≥n en `NavigationThread` con event loop dedicado (evita conflictos con FastMCP/uvicorn)
8. Actualiza estado: `state = "NAVIGATING"`, `target_node = destination_id`
9. **NUEVO:** Al finalizar, guarda `last_heading` en `last_state.json` para pr√≥xima navegaci√≥n
10. Retorna mensaje inmediatamente (no bloquea)

Uso desde voz: "Vete al nodo 3" o "Navega al nodo 5 desde el nodo 0"

### 3. emergency_stop()

Detiene inmediatamente el robot y cancela cualquier misi√≥n de navegaci√≥n activa.

Retorna: Mensaje confirmando acciones tomadas
```
"Parada de emergencia solicitada. Misi√≥n cancelada. Motores detenidos."
```

Comportamiento interno:
1. Cancela `mission_task` si existe (asyncio.Task)
2. Env√≠a `robot.set_wheel_speeds(0, 0)` al hardware
3. Actualiza estado: `state = "IDLE"`, `target_node = None`
4. Guarda estado en `last_state.json`

Uso desde voz: "¬°Para!" o "Detente" o "Alto"

### 4. get_robot_status()

Consulta el estado actual del robot para monitoreo.

Retorna: Diccionario con estado estructurado
```json
{
  "state": "NAVIGATING",
  "current_node": 0,
  "target_node": 3,
  "last_heading": 90.5,
  "robot_connected": true,
  "last_message": "Iniciando ruta: 0 -> 3.",
  "position": {"x": 0.0, "y": 0.0, "theta": 90.0},
  "mission_completed": false
}
```

Valores posibles de `state`:
- "IDLE": Robot en reposo, sin misi√≥n activa
- "NAVIGATING": Robot ejecutando navegaci√≥n hacia target_node
- "ERROR": Error en √∫ltima operaci√≥n

Uso desde voz: "¬øC√≥mo vas?" o "¬øCu√°l es tu estado?" o "¬øD√≥nde est√°s?"

## Ejemplos de Uso

### Ejemplo 1: Primera Navegaci√≥n (sin estado previo)

Usuario: "¬øA d√≥nde puedes ir?"
- OpenAI llama: `list_available_locations()`
- Respuesta: Lista de 15 nodos con nombres
- Usuario escucha: "Puedo ir a los siguientes lugares: inicio, izq_0, izq_1..."

Usuario: "Vete al nodo 3"
- OpenAI llama primero: `get_robot_status()` para obtener `current_node`
- Respuesta: `{"current_node": 0, "last_heading": 90.0, ...}`
- OpenAI llama: `navigate_robot(destination_id=3, origin_id=0)`
- **NUEVO:** Sistema obtiene heading real del robot (ej: 89.9¬∞) antes de iniciar
- Robot calcula ruta: 0 ‚Üí 5 ‚Üí 1 ‚Üí 2 ‚Üí 3 (Dijkstra)
- Robot inicia navegaci√≥n f√≠sica en background usando heading real
- Usuario escucha: "De acuerdo, yendo al nodo 3"
- Al llegar, sistema guarda `current_node=3` y `last_heading=45.2¬∞` en `last_state.json`

### Ejemplo 2: Navegaciones Subsecuentes

Usuario: "Ahora ve al nodo 5"
- OpenAI llama primero: `get_robot_status()` para obtener `current_node`
- Respuesta: `{"current_node": 3, "last_heading": 45.2, ...}`
- OpenAI llama: `navigate_robot(destination_id=5, origin_id=3)`
- **NUEVO:** Sistema obtiene heading real del robot (45.2¬∞) antes de iniciar
- **NUEVO:** Usa heading real en lugar del theta del grafo (cr√≠tico para navegaci√≥n consecutiva)
- Robot calcula ruta: 3 ‚Üí 2 ‚Üí 1 ‚Üí 5
- Robot navega autom√°ticamente con transformaci√≥n de coordenadas correcta

### Ejemplo 3: Parada de Emergencia

Usuario: "¬°Para!"
- OpenAI llama: `emergency_stop()` inmediatamente
- Robot cancela misi√≥n activa
- Robot env√≠a `set_wheel_speeds(0, 0)` al hardware
- Estado cambia a "IDLE"
- Usuario escucha: "Parada de emergencia ejecutada"

### Ejemplo 4: Consulta de Estado

Usuario: "¬øC√≥mo vas?"
- OpenAI llama: `get_robot_status()`
- Respuesta: `{"state": "NAVIGATING", "current_node": 3, "target_node": 5, ...}`
- Usuario escucha: "Estoy navegando hacia el nodo 5, actualmente desde el nodo 3"

## Testing

### Test 1: Health Check del Bridge

```bash
curl http://localhost:8000/health
```

Respuesta esperada:
```json
{
  "status": "ok",
  "service": "Robot Create3 Bridge",
  "openai_configured": true
}
```

### Test 2: Interfaz Web

1. Iniciar bridge: `python robot_bridge.py`
2. Abrir navegador: http://localhost:8000
3. Verificar que carga la interfaz correctamente
4. Clic en "Iniciar Sesi√≥n de Voz"
5. Verificar conexi√≥n WebSocket exitosa (status cambia a "Conectado")

### Test 3: Comando de Voz Simple

1. Decir: "¬øA d√≥nde puedes ir?"
2. Verificar en interfaz:
   - Transcripci√≥n aparece en panel izquierdo
   - Se ejecuta `list_available_locations()` (visible en logs)
   - Robot responde con lista de nodos
   - Audio se reproduce en el navegador

### Test 4: Navegaci√≥n Completa

1. Decir: "Vete al nodo 3 desde el nodo 0"
2. Verificar:
   - Se llama `navigate_robot(destination_id=3, origin_id=0)`
   - Robot confirma inicio de navegaci√≥n
   - Estado del robot se actualiza en UI (target_node=3)
   - Robot f√≠sico se mueve (si est√° conectado por Bluetooth)

### Test 5: Telemetr√≠a en Vivo (NUEVO)

1. Ejecutar suite de pruebas de telemetr√≠a:
   ```bash
   python test_telemetry.py
   ```
2. Verificar que pasan 3/3 pruebas:
   - Registro de callback
   - Status incluye posici√≥n
   - Simulaci√≥n de telemetr√≠a

3. Prueba en vivo con el bridge:
   - Iniciar navegaci√≥n hacia cualquier nodo
   - Observar panel "Posici√≥n en Vivo" en la interfaz web
   - Verificar que X, Y, Œ∏ se actualizan cada ~500ms
   - Verificar animaci√≥n amarilla en valores al actualizar
   - Al completar, verificar mensaje "‚úÖ Misi√≥n completada"

## Debugging

### Logs del Sistema

Todos los logs van a stderr, no stdout (stdout est√° reservado para protocolo MCP):

- `robot_bridge.py`: Logs en consola donde se ejecuta
- `mcp_server.py`: Logs a stderr (autom√°tico cuando se ejecuta como subproceso)
- `robot_service.py`: Logs a stderr con prefijo `[RobotService]`

Para capturar logs:
```bash
python robot_bridge.py 2> bridge.log
```

### Verificar Estado Persistente

```bash
cat last_state.json
# o en Windows:
type last_state.json
```

### Verificaci√≥n Pre-Demo (Checklist Cr√≠tico)

Antes de hacer una demostraci√≥n en vivo, **VERIFICA ESTOS PUNTOS:**

#### ‚úÖ Audio Funciona
```bash
# 1. Verifica que pydub est√° instalado
python -c "from pydub import AudioSegment; print('OK')"

# 2. Verifica que ffmpeg est√° en el PATH
ffmpeg -version

# 3. Si fallas, instala:
pip install pydub
# Y descarga ffmpeg de https://ffmpeg.org/
```

**S√≠ntoma de fallo:** OpenAI no transcribe nada, o transcribe basura.  
**Causa:** Audio WebM no convertido a PCM16.

#### ‚úÖ Lista de Nodos Cargada
```bash
# Iniciar bridge y verificar logs:
python robot_bridge.py

# Busca en la salida:
# "Lista de nodos obtenida para prompt de IA"
```

**S√≠ntoma de fallo:** La IA dice cosas como "No s√© qu√© nodos existen".  
**Causa:** MCP no pudo obtener `list_available_locations()` al inicio.

#### ‚úÖ Robot Conectado por Bluetooth
- Verifica que `config.py` tiene el nombre correcto: `BLUETOOTH_NAME = "iRobot-..."`
- El robot debe estar encendido y en rango
- Primera conexi√≥n puede tardar ~30 segundos

#### ‚úÖ OpenAI API Key V√°lida
```bash
# Verifica que .env existe:
cat .env  # o "type .env" en Windows

# Verifica que la key es v√°lida:
curl https://api.openai.com/v1/models \
  -H "Authorization: Bearer $OPENAI_API_KEY"
```

### Problemas Comunes y Soluciones

#### Error: "ModuleNotFoundError: No module named 'mcp'"
Soluci√≥n: `pip install mcp`

#### Error: "OPENAI_API_KEY no est√° configurada"
Causa: Falta archivo `.env` o variable no est√° definida
Soluci√≥n: Crear `.env` con `OPENAI_API_KEY=sk-proj-tu-clave`

#### Error: "ERROR: No s√© d√≥nde est√° el robot"
Causa: Primera navegaci√≥n sin `origin_id` y `current_node` es None
Soluci√≥n: Proporcionar `origin_id` expl√≠citamente en la primera navegaci√≥n, o editar `last_state.json`:
```json
{"current_node": 0, "last_message": "Posici√≥n inicial"}
```

#### Error: "El robot ya est√° en movimiento"
Causa: Intentar navegar mientras `state == "NAVIGATING"`
Soluci√≥n: Llamar primero `emergency_stop()`, luego `navigate_robot()`

#### Error: "Connection refused" al conectar WebSocket
Causa: `robot_bridge.py` no est√° corriendo
Soluci√≥n: Iniciar bridge con `python robot_bridge.py`

#### Audio no se escucha en el navegador
Causa: Posible problema de codec o formato de audio
Soluci√≥n temporal: Verificar que el navegador soporte WebRTC y audio PCM16. Revisar consola del navegador para errores de audio.

#### MCP Server no arranca desde bridge
Causa: Error en `mcp_server.py` o `robot_service.py` al inicializar
Soluci√≥n: Verificar logs en consola del bridge. Probar ejecutar `python -u mcp_server.py` directamente para ver errores.

## Sistema de Navegaci√≥n Subyacente

El sistema de navegaci√≥n f√≠sica del robot (implementado en `PRM02_P02_EQUIPO1_grafos.py` y `src/potential_fields.py`) utiliza una arquitectura h√≠brida de planificaci√≥n global + navegaci√≥n reactiva:

### Planificaci√≥n Global

Algoritmo de Dijkstra ejecutado sobre el grafo topol√≥gico (`grafos/prueba.py`) para calcular la ruta √≥ptima entre nodos. El grafo contiene:
- 31 nodos con coordenadas espaciales (x, y, theta) en cent√≠metros y grados
- Aristas bidireccionales con pesos que representan coste de navegaci√≥n
- Nombres descriptivos para cada nodo (inicio, izq_0, med_0, etc.)

**Proceso de planificaci√≥n:**
1. Usuario solicita navegaci√≥n: `navigate_robot(destination_id=5, origin_id=0)`
2. Sistema calcula camino m√≠nimo: `graph.Camino_Minimo_Dijkstra(0, 5)` ‚Üí `[0, 5]`
3. Extrae coordenadas de cada nodo del camino
4. Construye `q_i` (posici√≥n inicial), `waypoints` (intermedios), `q_f` (destino final)
5. **NUEVO:** Obtiene heading real del robot antes de usar `q_i` (cr√≠tico para transformaci√≥n correcta)

### Navegaci√≥n Reactiva con Campos de Potencial Combinados

Campos de potencial combinados implementados en `CombinedPotentialNavigator`:

#### Potencial Atractivo (Linear)
- **Fuerza:** Proporcional a la distancia hacia el waypoint actual
- **Ganancia:** `K_LINEAR = 0.25` (desde config.py)
- **Ganancia angular:** `K_ANGULAR = 3.0` para correcci√≥n de orientaci√≥n r√°pida
- **Funci√≥n:** `F_attractive = K_LINEAR * distance_to_goal`

#### Potencial Repulsivo (Evasi√≥n de Obst√°culos)
- **Modelo:** Basado en **clearance** (distancia libre despu√©s del radio del robot)
- **Ganancia:** `K_REPULSIVE = 300.0`
- **Rango de influencia:** `D_INFLUENCE = 100.0 cm` (obst√°culos m√°s lejos no generan fuerza)
- **Distancia de seguridad:** `D_SAFE = 20.0 cm` (clearance m√≠nimo recomendado)
- **Modelo f√≠sico:** Conversi√≥n IR ‚Üí distancia con compensaci√≥n por √°ngulo del sensor
- **7 sensores IR:** Cada sensor tiene factor de normalizaci√≥n espec√≠fico y √°ngulo conocido
- **Fuerza repulsiva:** Aumenta dr√°sticamente cuando `clearance < D_SAFE`
  - Clearance cr√≠tico (<1cm): Fuerza m√°xima
  - Clearance insuficiente (<20cm): `F = k_rep * ((1/clearance) - (1/d_safe))¬≤`
  - Clearance suficiente: `F = k_rep * (d_safe/clearance)¬≥ * factor_alcance`

**Problema Identificado:** En espacios reducidos, los nodos pueden estar cerca de paredes (ej: nodo a 25cm, pared a 29cm). El umbral actual hace que el robot evite la pared y no pueda llegar al nodo.

**Soluci√≥n Propuesta (Pendiente de Implementaci√≥n):**
- Umbrales adaptativos seg√∫n proximidad al waypoint:
  - Si `distance_to_goal < 30cm` y `velocity < 10 cm/s`: Reducir `D_INFLUENCE` y `IR_THRESHOLD_DETECT`
  - Esto permite acercarse m√°s a obst√°culos cuando est√° cerca del destino
- Ajuste seg√∫n velocidad:
  - Velocidad alta: Mantener umbrales actuales (seguridad)
  - Velocidad baja: Reducir umbrales (precisi√≥n)

#### Control Din√°mico de Velocidad
- **Velocidad m√°xima:** `V_MAX_CM_S = 38.0 cm/s`
- **Sistema de umbrales escalonados:** Reducci√≥n progresiva seg√∫n nivel de peligro
  - Emergency: `IR_THRESHOLD_EMERGENCY = 700` ‚Üí Velocidad muy reducida
  - Critical: `IR_THRESHOLD_CRITICAL = 350` ‚Üí Velocidad reducida
  - Warning: `IR_THRESHOLD_WARNING = 200` ‚Üí Velocidad moderada
  - Caution: `IR_THRESHOLD_CAUTION = 100` ‚Üí Velocidad normal con precauci√≥n
- **Rampa de aceleraci√≥n:** `ACCEL_RAMP_CM_S2 = 10.0` (previene cambios bruscos)
- **Zona de desaceleraci√≥n:** `DECEL_ZONE_CM = 50.0` (comienza a reducir velocidad)

#### Navegaci√≥n Secuencial
- El robot recorre waypoints intermedios en orden: `q_i ‚Üí wp1 ‚Üí wp2 ‚Üí ... ‚Üí q_f`
- Cada waypoint se alcanza con tolerancia adaptativa (5-8cm seg√∫n distancia recorrida)
- Al alcanzar un waypoint, pasa autom√°ticamente al siguiente
- Al alcanzar `q_f`, la misi√≥n se completa

#### Transformaci√≥n de Coordenadas (CR√çTICO)
- **Problema:** El robot usa odometr√≠a que empieza en (0,0) despu√©s de `reset_navigation()`
- **Soluci√≥n:** Transformaci√≥n completa (rotaci√≥n + traslaci√≥n) al sistema mundial
- **Heading real:** Se obtiene antes de iniciar navegaci√≥n (no el theta del grafo)
- **C√°lculo:** `odometry_to_world_rotation = desired_heading - reset_heading`
- **Aplicaci√≥n:** Todas las lecturas de odometr√≠a se transforman al sistema mundial durante navegaci√≥n

### Par√°metros Calibrados

Todos los par√°metros est√°n en `src/config.py` y fueron calibrados experimentalmente:

- **Geometr√≠a del robot:** `ROBOT_RADIUS_CM = 17.095`, `WHEEL_BASE_CM = 23.5`
- **Sensores IR:** 7 sensores con factores de normalizaci√≥n espec√≠ficos por sensor
- **√Ångulos de sensores:** `IR_SENSOR_ANGLES = {-60, -30, 0, 30, 60, 90, 120}` grados
- **Umbrales de seguridad:** `IR_THRESHOLD_EMERGENCY = 700`, `IR_THRESHOLD_CRITICAL = 350`, etc.
- **Tolerancia de llegada:** `TOL_DIST_CM = 3.0` base, adaptativa hasta 8cm seg√∫n distancia recorrida
- **Per√≠odo de control:** `CONTROL_DT = 0.05` (20 Hz)

### Integraci√≥n con MCP

El sistema MCP NO modifica la l√≥gica de navegaci√≥n existente. Simplemente:
- Expone `CombinedPotentialNavigator` como herramienta MCP
- Usa exactamente los mismos par√°metros calibrados
- Mantiene el tipo de potencial fijo en 'linear' (m√°s probado y estable)
- **NUEVO:** Crea navegador con `disable_logging=True` para evitar conflictos de event loop
- **NUEVO:** Ejecuta navegaci√≥n en `NavigationThread` con event loop dedicado
- **NUEVO:** Obtiene heading real antes de iniciar (no usa theta del grafo)
- Preserva toda la robustez del sistema original

## Correcciones Cr√≠ticas Implementadas

### ‚úÖ PUNTO CR√çTICO: Conflictos de Event Loop (CORREGIDO)

**El Problema Identificado:**
El SDK de iRobot (`robot.play()`) crea su propio event loop interno. Cuando se ejecuta en modo MCP, hay m√∫ltiples event loops ejecut√°ndose simult√°neamente:
- FastMCP/uvicorn (event loop del servidor web)
- `robot.play()` (daemon thread con su propio event loop)
- `NavigationThread` (crea su propio event loop para navegaci√≥n)

Los loggers (`SensorLogger` y `VelocityLogger`) usan `asyncio.Lock` que se vincula al event loop donde se crean, causando errores cuando se usan desde otro event loop:
```
‚ö†Ô∏è Error en logger: <asyncio.locks.Lock object at ...> is bound to a different event loop
```

**La Soluci√≥n Implementada:**
1. **NavigationThread con event loop dedicado:** La navegaci√≥n se ejecuta en un thread separado con `asyncio.new_event_loop()` para evitar conflictos
2. **Deshabilitaci√≥n de loggers en modo MCP:** `CombinedPotentialNavigator` ahora acepta par√°metro `disable_logging=True` que evita crear loggers que causan conflictos
3. **Reducci√≥n de frecuencia de polling:** Polling de telemetr√≠a reducido de 500ms a 1 segundo para reducir carga

**C√≥digo relevante:**
```python
# En robot_service.py
self.navigator_instance = CombinedPotentialNavigator(
    self.controller.robot, q_i, waypoints, q_f,
    disable_logging=True  # Evita conflictos de event loop
)

# NavigationThread crea su propio event loop
self.loop = asyncio.new_event_loop()
asyncio.set_event_loop(self.loop)
self.loop.run_until_complete(self._run_mission())
```

**Resultado:** ‚úÖ Navegaci√≥n funciona correctamente sin errores de event loop

### ‚úÖ PUNTO CR√çTICO: Navegaci√≥n Consecutiva con Heading Correcto (CORREGIDO)

**El Problema Identificado:**
Cuando el robot navega consecutivamente (ej: 0‚Üí5, luego 5‚Üí2), el sistema usaba el theta almacenado en el grafo (ej: 0¬∞) en lugar del heading real del robot cuando lleg√≥ al nodo 5 (ej: 45¬∞). Esto causaba transformaci√≥n de coordenadas incorrecta y navegaci√≥n err√≥nea.

**La Soluci√≥n Implementada:**
1. **Guardado de heading en last_state.json:** Al finalizar cada navegaci√≥n, se guarda el heading real del robot
2. **Obtenci√≥n de heading real antes de navegar:** En `_run_mission()`, se lee el heading real del robot antes de iniciar navegaci√≥n
3. **Prioridad de heading:** 
   - Primero: Heading real del robot (si disponible)
   - Segundo: `last_heading` guardado en disco (si existe)
   - Tercero: Theta del grafo (valor por defecto)

**C√≥digo relevante:**
```python
# En robot_service.py _run_mission()
try:
    pos = await self.controller.robot.get_position()
    if pos is not None:
        actual_theta = pos.heading  # Heading REAL del robot
    elif self.controller.last_heading is not None:
        actual_theta = self.controller.last_heading  # Heading guardado
except:
    actual_theta = q_i_node["theta"]  # Theta del grafo (fallback)

# Al finalizar navegaci√≥n
final_pos = await self.controller.robot.get_position()
if final_pos is not None:
    self.controller.last_heading = final_pos.heading
    self.controller._write_state_to_disk()
```

**Resultado:** ‚úÖ Navegaci√≥n consecutiva funciona correctamente con transformaci√≥n de coordenadas precisa

## Revisi√≥n Cr√≠tica de Arquitectura

### ‚úÖ PUNTO 1: "Fire and Forget" Disconnection (CORREGIDO)

**El Problema Identificado:**
La herramienta `navigate_robot` retorna inmediatamente con "RECIBIDO: Iniciando navegaci√≥n...", lo que hace que OpenAI piense que la misi√≥n est√° completa cuando apenas empieza. Si el robot falla 10 segundos despu√©s (deadlock, trampa local), OpenAI no se entera a menos que el usuario pregunte expl√≠citamente.

**La Soluci√≥n Implementada:**
- En `robot_bridge.py`, el bucle `telemetry_polling()` detecta cambios de estado
- Cuando `mission_completed` cambia de `False` ‚Üí `True`, inyectamos un mensaje en la conversaci√≥n de OpenAI:
  ```python
  await self.openai_ws.send(json.dumps({
      "type": "conversation.item.create",
      "item": {
          "type": "message",
          "role": "user",
          "content": [{
              "type": "input_text",
              "text": "[SYSTEM ALERT] Navegaci√≥n completada exitosamente. ..."
          }]
      }
  }))
  await self.openai_ws.send(json.dumps({"type": "response.create"}))
  ```
- Lo mismo para errores: inyectamos `[SYSTEM ERROR] La navegaci√≥n fall√≥. ...`

**Resultado:** OpenAI ahora se entera autom√°ticamente cuando las misiones terminan (√©xito o fallo) sin necesidad de que el usuario pregunte.

### ‚úÖ PUNTO 2: Race Conditions en State Management (CORREGIDO)

**El Problema Identificado:**
`last_state.json` se escribe desde m√∫ltiples funciones async sin protecci√≥n. Si `emergency_stop()` y `_run_mission()` intentan escribir simult√°neamente, podr√≠amos corromper el archivo o tener dirty reads.

**La Soluci√≥n Implementada:**
- Agregado `self.state_lock = asyncio.Lock()` en `RobotController.__init__()`
- Creadas dos versiones de `save_state()`:
  - `save_state()`: Versi√≥n sync para c√≥digo s√≠ncrono (ej: `start_navigation()`)
  - `save_state_async()`: Versi√≥n async con lock para c√≥digo async
- Todas las operaciones cr√≠ticas ahora usan lock:
  ```python
  async with self.state_lock:
      self.state = "IDLE"
      self.current_node = dest_node
      # ... operaciones at√≥micas ...
  
  await self.save_state_async()  # Escritura protegida
  ```
- `get_status()` ahora tambi√©n usa lock para lecturas at√≥micas
- File I/O se ejecuta en thread pool v√≠a `run_in_executor()` para no bloquear el event loop

**Resultado:** Todas las operaciones de estado son ahora at√≥micas y thread-safe.

### ‚ö†Ô∏è PUNTO 3: CombinedPotentialNavigator Initialization (YA CORRECTO)

**La Preocupaci√≥n:**
Re-instanciar `CombinedPotentialNavigator` en cada misi√≥n podr√≠a causar overhead de reconexi√≥n Bluetooth o recalibraci√≥n de sensores.

**An√°lisis del C√≥digo:**
Revisando `PRM02_P02_EQUIPO1_grafos.py` l√≠neas 361-391, el `__init__` solo hace:
- Asignaci√≥n de referencias (`self.robot = robot`)
- Creaci√≥n de loggers (ligero)
- **NO** hace conexi√≥n Bluetooth (recibe objeto `robot` ya conectado)
- **NO** hace calibraci√≥n de sensores

**Conclusi√≥n:** La implementaci√≥n actual es correcta. No hay overhead significativo porque:
1. El objeto `robot` se reutiliza (conexi√≥n persistente en `robot_service.py`)
2. El `__init__` es extremadamente ligero (<1ms)
3. Cada misi√≥n necesita waypoints diferentes, re-instanciar es apropiado

**Validaci√≥n Sugerida:** Medir tiempo entre "RECIBIDO" y primer movimiento de ruedas. Debe ser <500ms (tiempo de planificaci√≥n Dijkstra, no inicializaci√≥n).

### üî¥ Problema #1: Audio WebM ‚Üí PCM16 (CORREGIDO)

**El Problema:**
Los navegadores env√≠an audio en formato WebM/Opus por defecto. La API Realtime de OpenAI requiere PCM16 (raw audio) a 24kHz mono. Enviar WebM directamente causa que OpenAI reciba ruido est√°tico y no transcriba nada.

**La Soluci√≥n Implementada:**
- Funci√≥n `convert_webm_to_pcm16()` en `robot_bridge.py`
- Usa `pydub` + `ffmpeg` para decodificar en tiempo real
- Conversi√≥n autom√°tica: WebM/Opus ‚Üí PCM16 mono 24kHz
- Fallback si la conversi√≥n falla (con advertencia en logs)

**C√≥digo relevante (robot_bridge.py l√≠neas 90-128):**
```python
def convert_webm_to_pcm16(webm_data: bytes) -> bytes:
    audio = AudioSegment.from_file(io.BytesIO(webm_data), format="webm")
    audio = audio.set_channels(1)  # Mono
    audio = audio.set_frame_rate(24000)  # 24kHz
    audio = audio.set_sample_width(2)  # 16-bit
    return audio.raw_data
```

### üü° Problema #2: Alucinaciones de IDs de Nodos (CORREGIDO)

**El Problema:**
La IA puede inventar IDs de nodos inexistentes porque no conoce a priori qu√© lugares existen en el mapa. Esto genera errores al intentar navegar.

**La Soluci√≥n Implementada:**
- Al conectar a MCP, se llama `list_available_locations()` autom√°ticamente
- La lista completa de nodos se inyecta din√°micamente en `SYSTEM_INSTRUCTIONS`
- La IA ahora conoce desde el inicio: ID 0: inicio, ID 1: izq_0, etc.
- Instrucci√≥n expl√≠cita: "IMPORTANTE: Estos son los √öNICOS nodos v√°lidos. NO inventes IDs"

**C√≥digo relevante (robot_bridge.py l√≠neas 215-228):**
```python
# Obtener lista de nodos para inyectar en el prompt
result = await self.mcp_session.call_tool("list_available_locations", {})
self.node_list = content_item.text

# M√°s tarde, al configurar OpenAI:
system_instructions = get_system_instructions(self.node_list)
# Esto inyecta: "MAPA DEL ROBOT (Nodos disponibles): ..."
```

**Resultado:**
- ‚úÖ La IA no necesita llamar `list_available_locations()` cada vez
- ‚úÖ Reduce latencia (una llamada menos por conversaci√≥n)
- ‚úÖ Elimina alucinaciones de nombres/IDs inexistentes

## Implementaci√≥n T√©cnica del Bridge Server

### Arquitectura del Bridge (robot_bridge.py)

El bridge server implementa tres conexiones simult√°neas:

1. **Conexi√≥n con Browser (WebSocket)**: Recibe audio del micr√≥fono del usuario y env√≠a respuestas de voz de la IA
2. **Conexi√≥n con OpenAI Realtime API (WebSocket)**: Env√≠a audio del usuario, recibe transcripciones y llamadas a herramientas
3. **Conexi√≥n con MCP Server (stdio)**: Ejecuta `mcp_server.py` como subproceso y comunica mediante JSON-RPC 2.0

### Clase BridgeSession

La clase `BridgeSession` gestiona el ciclo de vida completo de una sesi√≥n:

- `connect_to_mcp()`: Inicia `mcp_server.py` como subproceso usando `mcp.client.stdio`, descubre herramientas disponibles y las convierte al formato OpenAI
- `connect_to_openai()`: Establece conexi√≥n WebSocket con OpenAI Realtime API, configura la sesi√≥n con herramientas MCP, instrucciones del sistema y par√°metros de audio
- `communication_loop()`: Ejecuta dos tareas en paralelo:
  - `browser_to_openai()`: Recibe audio del browser, convierte a base64 y reenv√≠a a OpenAI
  - `openai_to_browser_and_mcp()`: Procesa eventos de OpenAI (transcripciones, audio de respuesta, llamadas a herramientas) y los enruta apropiadamente
- `handle_tool_call()`: Ejecuta herramientas MCP cuando OpenAI las solicita, formatea resultados y los retorna a OpenAI para generar respuesta de voz

### Manejo de Audio

El bridge maneja audio en formato PCM16 de 24kHz:
- Browser env√≠a audio WebM que se convierte a base64 para OpenAI
- OpenAI env√≠a audio PCM16 en base64 que se decodifica y reenv√≠a al browser
- La conversi√≥n de formatos se maneja autom√°ticamente por las librer√≠as

### Configuraci√≥n de OpenAI Realtime

El bridge configura la sesi√≥n de OpenAI con:
- Modalities: text y audio habilitados
- Voice: "alloy" (puede cambiarse en `SYSTEM_INSTRUCTIONS`)
- Input/Output audio format: PCM16
- Transcription model: Whisper-1
- Turn detection: Server VAD (Voice Activity Detection) con umbral 0.5
- Tool choice: "auto" (OpenAI decide cu√°ndo llamar herramientas)
- Temperature: 0.8 para respuestas m√°s naturales

### Instrucciones del Sistema

Las instrucciones del sistema (`SYSTEM_INSTRUCTIONS`) gu√≠an el comportamiento de la IA:

**REGLAS CR√çTICAS PARA NAVEGACI√ìN:**
1. SIEMPRE necesitas DOS valores para navegar: `origin_id` (de d√≥nde sale) y `destination_id` (a d√≥nde va)
2. Si el usuario NO especifica el nodo origen EXPL√çCITAMENTE con un n√∫mero:
   - PRIMERO llama a `get_robot_status()` para obtener el `current_node`
   - LUEGO usa ese `current_node` como `origin_id`
3. Si el usuario dice "el √∫ltimo", "donde est√°", "donde qued√≥", "su posici√≥n actual":
   - DEBES llamar a `get_robot_status()` primero
   - Usa el `current_node` de la respuesta como `origin_id`
4. NUNCA llames a `navigate_robot()` sin tener AMBOS valores confirmados
5. Si el usuario dice "del nodo X al Y" ‚Üí `origin_id=X`, `destination_id=Y`
6. Si el usuario solo dice "ve al nodo Y" sin especificar origen ‚Üí llama `get_robot_status()` primero

**Otras instrucciones:**
- Explican las 4 herramientas MCP disponibles
- Instruyen a la IA a usar `list_available_locations()` primero cuando el usuario pregunta por lugares
- Enfatizan el uso de IDs num√©ricos exactos (no inventar n√∫meros)
- Instruyen a llamar `emergency_stop()` inmediatamente si el usuario dice "para" o "detente"

## Detalles de Implementaci√≥n

### Gesti√≥n de Estado Persistente

El archivo `last_state.json` se actualiza autom√°ticamente cuando:
- Una misi√≥n de navegaci√≥n termina exitosamente (`current_node` se actualiza al destino)
- Se ejecuta `emergency_stop()` (estado se resetea a IDLE)

Formato del archivo:
```json
{
  "current_node": 3,
  "last_heading": 45.2,
  "last_message": "Llegada exitosa al Nodo 3."
}
```

**NUEVO:** El campo `last_heading` es cr√≠tico para navegaci√≥n consecutiva. Cuando el robot llega a un nodo desde cualquier direcci√≥n, su heading real puede ser diferente al theta almacenado en el grafo. El sistema ahora:
1. Guarda el heading real al finalizar cada navegaci√≥n
2. Usa este heading al iniciar la siguiente navegaci√≥n (en lugar del theta del grafo)
3. Esto asegura que la transformaci√≥n de coordenadas sea correcta en navegaciones consecutivas

Si el servidor crashea, el √∫ltimo estado conocido se mantiene y se carga al reiniciar.

### Conexi√≥n Bluetooth Persistente

La conexi√≥n al robot Create3 se establece una sola vez cuando se crea la instancia de `RobotController` en `robot_service.py`. La conexi√≥n se mantiene durante toda la vida del servidor MCP, evitando overhead de reconexi√≥n en cada comando.

### Navegaci√≥n As√≠ncrona con Event Loop Dedicado

**ARQUITECTURA ACTUALIZADA:** Las misiones de navegaci√≥n se ejecutan en `NavigationThread` (threading.Thread) con su propio event loop de asyncio para evitar conflictos con FastMCP/uvicorn:

- **NavigationThread:** Crea su propio `asyncio.new_event_loop()` para ejecutar `navigator.navigate()`
- **Deshabilitaci√≥n de loggers:** `CombinedPotentialNavigator` se crea con `disable_logging=True` para evitar conflictos de `asyncio.Lock` entre event loops
- **Obtenci√≥n de heading real:** Antes de iniciar navegaci√≥n, se lee el heading real del robot (no el theta del grafo)
- El servidor MCP no se bloquea durante navegaciones largas
- Se pueden recibir otros comandos (como `emergency_stop()`)
- El bridge puede seguir procesando llamadas de herramientas
- **Problema resuelto:** Evita errores de "Lock bound to different event loop" que causaban navegaci√≥n incorrecta

### Manejo de Errores

El sistema maneja errores en m√∫ltiples niveles:
- Validaci√≥n de par√°metros antes de iniciar navegaci√≥n
- Manejo de excepciones en bucles de control
- Cancelaci√≥n limpia de tareas as√≠ncronas
- Logging detallado a stderr para debugging

## M√©tricas del Proyecto

Archivos nuevos creados:
- `robot_bridge.py`: 490 l√≠neas (servidor bridge FastAPI + telemetr√≠a)
- `static/index.html`: 650 l√≠neas (interfaz web + posici√≥n en vivo)
- `robot_service.py`: 430 l√≠neas (controlador del robot + telemetr√≠a)
- `mcp_server.py`: 204 l√≠neas (servidor MCP)
- `test_mcp_server.py`: 296 l√≠neas (suite de pruebas base)
- `test_telemetry.py`: 190 l√≠neas (suite de pruebas telemetr√≠a)
- `last_state.json`: Estado persistente

Archivos existentes (sin modificaciones):
- `PRM02_P02_EQUIPO1_grafos.py`: 1057 l√≠neas
- `src/potential_fields.py`: 1557 l√≠neas
- `src/config.py`: 461 l√≠neas
- `grafos/prueba.py`: 408 l√≠neas

Total del sistema: ~5800 l√≠neas de c√≥digo Python/HTML/JS

Cobertura de pruebas:
- Suite base: 6/6 pruebas pasadas (imports, grafo, Dijkstra, controlador, nombres, persistencia)
- Suite telemetr√≠a: 3/3 pruebas pasadas (callback, status, simulaci√≥n)

## Notas T√©cnicas

- Conexi√≥n Persistente: El robot mantiene conexi√≥n Bluetooth durante toda la vida del servidor MCP
- Navegaci√≥n Async: Las misiones se ejecutan en background, el servidor no se bloquea
- Estado Seguro: Si el servidor crashea, el √∫ltimo estado conocido se mantiene en JSON
- Tipo de Potencial: Fijo en 'linear' por decisi√≥n de dise√±o (m√°s probado y estable)
- **Audio PCM16:** Conversi√≥n autom√°tica WebM ‚Üí PCM16 con pydub + ffmpeg (cr√≠tico para OpenAI)
- **Prompt Inyectado:** Lista de nodos pre-cargada en SYSTEM_INSTRUCTIONS para reducir alucinaciones
- **Telemetr√≠a en Vivo:** Sistema de polling a 1 Hz desde bridge (reducido de 2 Hz), 5 Hz desde robot durante navegaci√≥n
- **Detecci√≥n Autom√°tica:** El bridge detecta finalizaci√≥n de misiones sin intervenci√≥n de OpenAI
- **Eventos As√≠ncronos:** Tres bucles paralelos (audio, OpenAI, telemetr√≠a) ejecut√°ndose simult√°neamente
- **Event Loop Dedicado:** NavigationThread con su propio event loop evita conflictos con FastMCP/uvicorn
- **Logging Deshabilitado:** `disable_logging=True` en modo MCP evita conflictos de asyncio.Lock
- **Heading Persistente:** `last_heading` guardado en `last_state.json` para navegaci√≥n consecutiva correcta
- **Instrucciones Mejoradas:** Sistema de IA ahora requiere `origin_id` expl√≠cito, llama `get_robot_status()` si no lo conoce
- Windows Compatible: Probado en Windows 10/11 con Python 3.x
- Buffering: El bridge ejecuta `mcp_server.py` con flag `-u` autom√°ticamente para evitar problemas de buffering en Windows

### Mejoras Futuras Opcionales

**1. Telemetr√≠a con Server-Sent Events (MCP Nativo):**
- Actualmente: Polling cada 1 segundo (reducido de 500ms para evitar conflictos)
- Mejora: Usar Context de FastMCP para enviar actualizaciones proactivas
- Beneficio: Latencia m√°s baja (<50ms), menos overhead de red
- Trade-off: M√°s complejidad, MCP SSE tiene limitaciones para eventos push

**2. Umbrales Adaptativos de Obst√°culos (PENDIENTE DE IMPLEMENTACI√ìN):**
- **Problema Actual:** En espacios reducidos, los nodos pueden estar cerca de paredes (ej: nodo a 25cm, pared a 29cm). El umbral actual (`D_INFLUENCE = 100cm`, `IR_THRESHOLD_DETECT`) hace que el robot evite la pared y no pueda llegar al nodo.
- **Soluci√≥n Propuesta:** Sistema de umbrales adaptativos seg√∫n:
  - **Proximidad al waypoint:** Si `distance_to_goal < 30cm` ‚Üí Reducir `D_INFLUENCE` progresivamente (ej: 100cm ‚Üí 50cm ‚Üí 30cm)
  - **Velocidad del robot:** Si `velocity < 10 cm/s` ‚Üí Reducir `IR_THRESHOLD_DETECT` (permitir detecci√≥n m√°s cercana)
  - **Combinaci√≥n:** Cuando ambas condiciones se cumplen, el robot puede acercarse m√°s a obst√°culos para alcanzar el nodo
- **Beneficio:** Permite llegar a nodos cerca de paredes sin evitar obst√°culos innecesariamente
- **Implementaci√≥n Sugerida:** Modificar `repulsive_force()` en `src/potential_fields.py` para calcular umbrales din√°micos basados en `distance_to_goal` y `current_velocity`

**2. Visualizaci√≥n Gr√°fica del Mapa:**
- Canvas HTML5 para dibujar trayectoria en tiempo real
- Indicadores visuales de sensores IR (distancia a obst√°culos)
- Animaci√≥n del robot movi√©ndose en el mapa 2D

**3. Audio Bidireccional Optimizado:**
- Actualmente: Conversi√≥n completa por chunk (funcional pero CPU-intensivo)
- Mejora: Streaming pipeline con buffer circular
- Beneficio: Menor latencia, menor uso de CPU

## Autores

Alan Ariel Salazar  
Yago Ramos S√°nchez

Universidad Intercontinental de la Empresa (UIE)  
Curso: Robots Aut√≥nomos  
Profesor: Eladio Dapena  
Fecha: Noviembre 2025

